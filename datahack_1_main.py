# -*- coding: utf-8 -*-
"""Datahack_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a8NpRtl-7usq7ypRJeqJLOPBmVyenjPs
"""

import zipfile
from google.colab import drive
drive.mount('/content/drive/')

!ls 'drive/My Drive/data_hack'

ls

# !unzip 'drive/My Drive/data_hack/train.zip'

# !unzip 'drive/My Drive/data_hack/test.zip'

ls

# Commented out IPython magic to ensure Python compatibility.
#importing the libraries
import pandas as pd
import numpy as np

# for reading and displaying images
from skimage.io import imread
import matplotlib.pyplot as plt
# %matplotlib inline

#for creating validation set
from sklearn.model_selection import train_test_split

#for evaluating the model
from sklearn.metrics import accuracy_score
from tqdm import tqdm

#pytorch libraries and modules
import torch
from torch.autograd import variable
from torch.nn import Linear, ReLU, CrossEntropyLoss,Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.optim import Adam , SGD

from sklearn.model_selection import StratifiedKFold

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
sample = pd.read_csv('drive/My Drive/data_hack/sample_submission.csv')

# loading training images
train_img = []
for img_name in tqdm(train['id']):
    # defining the image path
    image_path = 'train/' + str(img_name) + '.png'
    # reading the image
    img = imread(image_path, as_gray=True)
    # normalizing the pixel values
    # converting the type of pixel to float 32
    img = img.astype('float32')
    # appending the image into the list
    train_img.append(img)

# converting the list to numpy array
train_x = np.array(train_img)
train_x.shape

ls

# loading training images
test_img = []
for img_name in tqdm(test['id']):
    # defining the image path
    image_path = 'test/' + str(img_name) + '.png'
    # reading the image
    img = imread(image_path, as_gray=True)
    # normalizing the pixel values
    # converting the type of pixel to float 32
    img = img.astype('float32')
    # appending the image into the list
    test_img.append(img)

# converting the list to numpy array
test_x = np.array(test_img)
test_x.shape



!mkdir image_pickles
!mkdir image_pickles_test

import joblib

# mkdir image_pickles_test

image_ids = train.id.values
# df = df.drop("image_id", axis=1)
image_array = train_x
for j, image_id in tqdm(enumerate(image_ids), total=len(image_ids)):
    joblib.dump(train_x[j, :], f"/content/image_pickles/{image_id}.pkl")

image_ids = test.id.values
# df = df.drop("image_id", axis=1)
image_array = test_x
for j, image_id in tqdm(enumerate(image_ids), total=len(image_ids)):
    joblib.dump(test_x[j, :], f"/content/image_pickles_test/{image_id}.pkl")

train.columns

import albumentations
import joblib

import pandas as pd

import torch

from PIL import Image
from albumentations.core.transforms_interface import ImageOnlyTransform
from albumentations.augmentations import functional as F1
from PIL import Image, ImageOps, ImageEnhance

from albumentations.core.transforms_interface import DualTransform

class GridMask(DualTransform):
    """GridMask augmentation for image classification and object detection.

    Args:
        num_grid (int): number of grid in a row or column.
        fill_value (int, float, lisf of int, list of float): value for dropped pixels.
        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int
            an angle is picked from (-rotate, rotate). Default: (-90, 90)
        mode (int):
            0 - cropout a quarter of the square of each grid (left top)
            1 - reserve a quarter of the square of each grid (left top)
            2 - cropout 2 quarter of the square of each grid (left top & right bottom)

    Targets:
        image, mask

    Image types:
        uint8, float32

    Reference:
    |  https://arxiv.org/abs/2001.04086
    |  https://github.com/akuxcw/GridMask
    """

    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):
        super(GridMask, self).__init__(always_apply, p)
        if isinstance(num_grid, int):
            num_grid = (num_grid, num_grid)
        if isinstance(rotate, int):
            rotate = (-rotate, rotate)
        self.num_grid = num_grid
        self.fill_value = fill_value
        self.rotate = rotate
        self.mode = mode
        self.masks = None
        self.rand_h_max = []
        self.rand_w_max = []

    def init_masks(self, height, width):
        if self.masks is None:
            self.masks = []
            n_masks = self.num_grid[1] - self.num_grid[0] + 1
            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):
                grid_h = height / n_g
                grid_w = width / n_g
                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)
                for i in range(n_g + 1):
                    for j in range(n_g + 1):
                        this_mask[
                             int(i * grid_h) : int(i * grid_h + grid_h / 2),
                             int(j * grid_w) : int(j * grid_w + grid_w / 2)
                        ] = self.fill_value
                        if self.mode == 2:
                            this_mask[
                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),
                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)
                            ] = self.fill_value
                
                if self.mode == 1:
                    this_mask = 1 - this_mask

                self.masks.append(this_mask)
                self.rand_h_max.append(grid_h)
                self.rand_w_max.append(grid_w)

    def apply(self, image, mask, rand_h, rand_w, angle, **params):
        h, w = image.shape[:2]
        mask = F1.rotate(mask, angle) if self.rotate[1] > 0 else mask
        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask
        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)
        return image

    def get_params_dependent_on_targets(self, params):
        img = params['image']
        height, width = img.shape[:2]
        self.init_masks(height, width)

        mid = np.random.randint(len(self.masks))
        mask = self.masks[mid]
        rand_h = np.random.randint(self.rand_h_max[mid])
        rand_w = np.random.randint(self.rand_w_max[mid])
        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0

        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}

    @property
    def targets_as_params(self):
        return ['image']

    def get_transform_init_args_names(self):
        return ('num_grid', 'fill_value', 'rotate', 'mode')

img_height=28
img_width=28
mean=[0.485, 0.456, 0.406]
std=[0.229, 0.224, 0.225]

from torch.utils.data.dataset import Dataset
from PIL import Image

class MnistDataset(Dataset):
  def __init__(self,df,transforms=None,train=True):
    self.train = train
    self.transforms = transforms
    self.id = df.id.values
    self.X = df.loc[:,df.columns!='label'].to_numpy(float)
    self.X = torch.from_numpy(self.X)
    print(type(self.X))
    if train:
      self.aug = albumentations.Compose([
                # albumentations.Resize(img_height, img_width, always_apply=True),
                albumentations.ShiftScaleRotate(shift_limit=0.0625,
                                               scale_limit=0.1, 
                                               rotate_limit=5,
                                               p=0.9),
                # albumentations.Normalize(mean, std, always_apply=True),
                albumentations.OneOf([
                    GridMask(num_grid=3, mode=0, rotate=15),
                    GridMask(num_grid=3, mode=2, rotate=15),
                ], p=0.75)
            ])
    else:
      self.aug = albumentations.Compose([
                # albumentations.Resize(img_height, img_width, always_apply=True),
                # albumentations.Normalize(mean, std, always_apply=True)
            ])
             
    if train:
      self.y = df.get('label').to_numpy()
      self.y = torch.from_numpy(self.y)
   
  def __len__(self):
     return self.X.shape[0]
   
  def __getitem__(self,i):
    if self.train:
      image = joblib.load(f"/content/image_pickles/{self.id[i]}.pkl")
    else:
      image = joblib.load(f"/content/image_pickles_test/{self.id[i]}.pkl")
    image = image/255
    image = torch.Tensor(image)
    image =  image.view(1, 28, 28).expand(3, 28, 28)
    # image = image.reshape(28, 28).astype(float)
    # image = Image.fromarray(image).convert("RGB")
    image = self.aug(image=np.array(image))["image"]
    # if self.transforms: x = self.transforms(x)
        
    if self.train: return image, self.y[i]
    return image



import torchvision.transforms as transforms
import  torchvision.transforms as transforms
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])

ds = MnistDataset(train,normalize)
len(ds)

val_len =int(len(ds)*0.01)
train_len = len(ds) - val_len
from torch.utils.data import random_split
train_ds,val_ds = random_split(ds,[train_len, val_len])
len(train_ds), len(val_ds)

from torch.utils.data.dataloader import DataLoader
bs = 128
num_workers = 2
train_dl = DataLoader(train_ds,bs,num_workers=num_workers)
val_dl = DataLoader(val_ds, bs, num_workers=num_workers)

images,labels = next(iter(train_dl))
images.shape, labels.shape

import torchvision.models as models
resnet34 = models.resnet152(pretrained=True)

resnet34.fc

lin_in = resnet34.fc.in_features

import torch.nn as nn

resnet34.fc = nn.Sequential(
    nn.Linear(lin_in, 10),
    nn.Softmax(dim=1)
)





net = resnet34
out = net(images.float())
out.shape

device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'
net = net.to(device)
device

epochs = 70
loss_fn = nn.CrossEntropyLoss()

import torch.optim as optim
optimizer = optim.Adam(net.parameters(),lr=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 
                                                            mode="max", 
                                                            patience=5, 
                                                            factor=0.3,verbose=True)

from datetime import datetime

losses = []
accuracies = []
for i in range(epochs):
    e_loss = 0
    start = datetime.now()
    # training
    for images, labels in train_dl:
        optimizer.zero_grad()
        
        images, labels = images.to(device,dtype=torch.float), labels.to(device)
        
        out = net(images)
        loss = loss_fn(out.float(), labels.long())
        loss.backward()
        
        e_loss += loss.item()
        
        optimizer.step()

    #validation
    with torch.no_grad():
        accuracy = 0
        for images, labels in val_dl:
            images, labels = images.to(device,dtype=torch.float), labels.to(device)
            out = net(images)
            accuracy+=(out.argmax(dim=1) == labels).sum().item()
        accuracies.append(accuracy/len(val_ds) * 100)
    scheduler.step(accuracies[-1])

    end = datetime.now()

    print(f'Epoch: {i}\tTime: {(end - start).total_seconds():.2f}s\tLoss: {e_loss:.2f}\tAccuracy: {accuracies[-1]:.2f}')
    losses.append(e_loss)

import matplotlib.pyplot as plt

plt.plot(range(epochs), accuracies)

bs = 640
test_ds = MnistDataset(test, normalize, train = False)
test_dl = DataLoader(test_ds, bs)

outputs = []
with torch.no_grad():
    for images in test_dl:
        images = images.to(device, dtype=torch.float)
        out = net(images)
        outputs.extend(out.argmax(dim=1).tolist())

len(outputs)

test.shape, sample.shape

sample['label'] = outputs
sample.to_csv('submission2.csv', index=False)

output = pd.read_csv('submission.csv')

output.head()

ls

cp 'submission2.csv'  'drive/My Drive'

